import * as FileSystem from 'expo-file-system/legacy';
import { Audio, InterruptionModeIOS, InterruptionModeAndroid } from 'expo-av';
import { TTSProvider, OpenAIVoice, WordTimestamp } from '../types';  // PHASE 2: Added WordTimestamp
import { STREAMING_CONFIG } from '../config/streaming-config';
import { cartesiaStreamingService } from './cartesia-streaming-service';
import { chunkedStreamingPlayer } from './streaming-audio-player';

/**
 * Text-to-Speech Service supporting Cartesia and OpenAI APIs
 * 
 * Uses raw fetch (no SDK) to avoid React Native incompatibility with Node.js modules.
 * 
 * NEW: Supports WebSocket streaming for Cartesia (Phase 1-3)
 */
class TTSService {
  private soundObjects: Audio.Sound[] = [];
  private isPlaying: boolean = false;
  private isInitialized: boolean = false;

  // NEW: Mute state
  private isMuted: boolean = false;

  // NEW: TTS Provider selection
  private ttsProvider: TTSProvider = 'cartesia';
  private openaiVoice: OpenAIVoice = 'nova';
  private openaiApiKey?: string;

  // NEW: Streaming state
  private isStreaming: boolean = false;
  private currentStreamContextId: string | null = null;

  constructor() {
    this.initialize();
    this.openaiApiKey = process.env.EXPO_PUBLIC_OPENAI_API_KEY;
    this.loadSettings();
  }

  private async initialize(): Promise<void> {
    if (this.isInitialized) return;

    try {
      console.log("üîä [TTS] Initializing audio...");

      await Audio.setAudioModeAsync({
        allowsRecordingIOS: false,
        playsInSilentModeIOS: true,
        staysActiveInBackground: false,
        shouldDuckAndroid: true,
        playThroughEarpieceAndroid: false,
        interruptionModeIOS: InterruptionModeIOS.DuckOthers,
        interruptionModeAndroid: InterruptionModeAndroid.DuckOthers
      });

      this.isInitialized = true;
      console.log("‚úÖ [TTS] Audio initialized");

    } catch (error) {
      console.error("‚ùå [TTS] Initialization failed:", error);
    }
  }

  // ========================
  // MUTE CONTROL
  // ========================

  /**
   * Set mute state
   */
  setMuted(muted: boolean): void {
    console.log(`üîá [TTS] Mute state changed: ${muted}`);
    this.isMuted = muted;

    // –ï—Å–ª–∏ –≤–∫–ª—é—á–∞–µ–º mute –≤–æ –≤—Ä–µ–º—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è - –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å
    if (muted && this.isPlaying) {
      console.log('üîá [TTS] Stopping playback due to mute');
      this.stop();
    }
  }

  /**
   * Get current mute state
   */
  getIsMuted(): boolean {
    return this.isMuted;
  }

  // ========================
  // TTS PROVIDER CONTROL
  // ========================

  /**
   * Set TTS provider
   */
  setTtsProvider(provider: TTSProvider): void {
    console.log(`üéôÔ∏è [TTS] Provider changed: ${this.ttsProvider} ‚Üí ${provider}`);
    this.ttsProvider = provider;
    this.saveSettings();
  }

  /**
   * Get current TTS provider
   */
  getTtsProvider(): TTSProvider {
    return this.ttsProvider;
  }

  /**
   * Set OpenAI voice
   */
  setOpenaiVoice(voice: OpenAIVoice): void {
    console.log(`üéôÔ∏è [TTS] OpenAI voice changed: ${this.openaiVoice} ‚Üí ${voice}`);
    this.openaiVoice = voice;
    this.saveSettings();
  }

  /**
   * Get current OpenAI voice
   */
  getOpenaiVoice(): OpenAIVoice {
    return this.openaiVoice;
  }

  // ========================
  // SETTINGS PERSISTENCE
  // ========================

  /**
   * Load settings from AsyncStorage
   */
  private async loadSettings(): Promise<void> {
    try {
      const AsyncStorage = await import('@react-native-async-storage/async-storage');
      const settings = await AsyncStorage.default.getItem('tts_settings');

      if (settings) {
        const parsed = JSON.parse(settings);
        this.ttsProvider = parsed.provider || 'cartesia';
        this.openaiVoice = parsed.voice || 'nova';
        console.log(`‚úÖ [TTS] Settings loaded: ${this.ttsProvider}/${this.openaiVoice}`);
      }
    } catch (error) {
      console.warn('‚ö†Ô∏è [TTS] Failed to load settings:', error);
    }
  }

  /**
   * Save settings to AsyncStorage
   */
  private async saveSettings(): Promise<void> {
    try {
      const AsyncStorage = await import('@react-native-async-storage/async-storage');
      await AsyncStorage.default.setItem('tts_settings', JSON.stringify({
        provider: this.ttsProvider,
        voice: this.openaiVoice,
      }));
      console.log('‚úÖ [TTS] Settings saved');
    } catch (error) {
      console.warn('‚ö†Ô∏è [TTS] Failed to save settings:', error);
    }
  }

  /**
   * Generate speech from text using selected provider
   * 
   * NEW: Automatically uses streaming for Cartesia if enabled (STREAMING_CONFIG.enabled)
   * Falls back to REST API on streaming errors
   */
  async speak(
    text: string,
    options?: {
      emotion?: string;
      speed?: number;
      emotionLevel?: string[];
      autoPlay?: boolean;
    }
  ): Promise<boolean> {
    // –ü–†–û–í–ï–†–ö–ê MUTE
    if (this.isMuted) {
      console.log(`üîá [TTS] Muted - skipping speech: "${text.substring(0, 30)}..."`);
      return true; // –í–æ–∑–≤—Ä–∞—â–∞–µ–º true —á—Ç–æ–±—ã –Ω–µ –ª–æ–º–∞—Ç—å –ª–æ–≥–∏–∫—É
    }

    try {
      console.log(`üéôÔ∏è [TTS] Speaking: "${text.substring(0, 50)}..."`);

      // NEW: Try streaming first if enabled and using Cartesia
      if (STREAMING_CONFIG.enabled && this.ttsProvider === 'cartesia') {
        console.log('üåä [TTS] Attempting streaming playback...');

        try {
          const success = await this.speakCartesiaStreaming(text, options);
          if (success) {
            console.log('‚úÖ [TTS] Streaming playback successful');
            return true;
          }

          console.warn('‚ö†Ô∏è [TTS] Streaming failed, falling back to REST API');
        } catch (error) {
          console.error('‚ùå [TTS] Streaming error, falling back to REST API:', error);
        }
      }

      // Standard (REST API) path
      const audioFile = await this.fetchAudioFile(text, options);

      if (!audioFile) {
        console.error("‚ùå [TTS] Failed to fetch audio");
        return false;
      }

      if (options?.autoPlay !== false) {
        return await this.playAudioFile(audioFile, options?.speed);
      }

      return true;

    } catch (error) {
      console.error("‚ùå [TTS] Speak error:", error);
      return false;
    }
  }

  /**
   * Fetch audio file - automatically selects provider
   */
  private async fetchAudioFile(
    text: string,
    options?: {
      emotion?: string;
      speed?: number;
      emotionLevel?: string[];
    }
  ): Promise<string | null> {
    try {
      // –í—ã–±–æ—Ä –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
      if (this.ttsProvider === 'openai') {
        console.log(`üéôÔ∏è [TTS] Using OpenAI TTS provider`);
        return await this.fetchOpenAIAudioFile(text, options);
      } else {
        console.log(`üéôÔ∏è [TTS] Using Cartesia TTS provider`);
        return await this.fetchCartesiaAudioFile(text, options);
      }
    } catch (error) {
      console.error('‚ùå [TTS] fetchAudioFile error:', error);
      return null;
    }
  }

  // ========================
  // OPENAI TTS METHODS
  // ========================

  /**
   * Fetch audio file from OpenAI API
   */
  private async fetchOpenAIAudioFile(
    text: string,
    options?: {
      emotion?: string; // Ignored in OpenAI, but kept for compatibility
      speed?: number;
      emotionLevel?: string[];
    }
  ): Promise<string | null> {
    try {
      if (!this.openaiApiKey) {
        console.error('‚ùå [TTS] OpenAI API key not configured');
        return null;
      }

      console.log(`üéôÔ∏è [TTS] OpenAI TTS request...`);
      console.log(`üéôÔ∏è [TTS] Text: "${text.substring(0, 50)}..."`);
      console.log(`üéôÔ∏è [TTS] Voice: ${this.openaiVoice}`);
      console.log(`üéôÔ∏è [TTS] Speed: ${options?.speed || 1.0}x`);

      // OpenAI API request
      const response = await fetch('https://api.openai.com/v1/audio/speech', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.openaiApiKey}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'tts-1',  // –∏–ª–∏ 'tts-1-hd' –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
          input: text,
          voice: this.openaiVoice,
          speed: options?.speed || 1.0,
          response_format: 'mp3',
        }),
      });

      console.log(`üì• [TTS] OpenAI Response status: ${response.status}`);

      if (!response.ok) {
        const errorText = await response.text();
        console.error(`‚ùå [TTS] OpenAI API Error:`, errorText);
        return null;
      }

      // –ü–æ–ª—É—á–∏—Ç—å –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ
      const arrayBuffer = await response.arrayBuffer();
      console.log(`‚úÖ [TTS] OpenAI Audio received: ${arrayBuffer.byteLength} bytes`);

      // –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ —Ñ–∞–π–ª
      const filename = `openai_speech_${Date.now()}.mp3`;
      const filepath = `${FileSystem.cacheDirectory}${filename}`;

      const base64Audio = this.arrayBufferToBase64(arrayBuffer);
      await FileSystem.writeAsStringAsync(filepath, base64Audio, {
        encoding: 'base64',
      });

      console.log(`üíæ [TTS] OpenAI Audio saved: ${filepath}`);
      return filepath;

    } catch (error) {
      console.error('‚ùå [TTS] OpenAI TTS error:', error);
      return null;
    }
  }

  // ========================
  // CARTESIA TTS METHODS
  // ========================

  /**
   * Fetch audio file from Cartesia API using raw fetch
   */
  private async fetchCartesiaAudioFile(
    text: string,
    options?: {
      emotion?: string;
      speed?: number;
      emotionLevel?: string[];
    }
  ): Promise<string | null> {
    try {
      console.log(`üéôÔ∏è [TTS] Starting Cartesia REST API call...`);
      console.log(`üéôÔ∏è [TTS] Text: "${text.substring(0, 50)}..."`);

      // ‚ö†Ô∏è TEMPORARY HARDCODE - FOR TESTING ONLY
      const API_KEY = "sk_car_8H5cHPGLMuZpaeXxqWNNve";  // ‚Üê Your real key from dashboard
      const VOICE_ID = "e07c00bc-4134-4eae-9ea4-1a55fb45746b";

      console.log("‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è [TTS] Using HARDCODED key (TEST MODE)");

      console.log(`üîë [TTS] Key loaded: ${API_KEY.substring(0, 25)}...`);
      console.log(`üé≠ [TTS] Emotion: ${options?.emotion || 'neutral'}`);
      console.log(`‚ö° [TTS] Speed: ${options?.speed || 1.0}x`);

      // Build request with emotion controls
      const requestBody: any = {
        model_id: "sonic-3",
        transcript: text,
        voice: {
          mode: "id",
          id: VOICE_ID
        },
        language: "en",
        output_format: {
          container: "mp3",
          encoding: "mp3",
          sample_rate: 44100
        }
      };

      // Add emotion controls if provided
      if (options?.emotion || options?.emotionLevel) {
        const emotionLevel = options.emotionLevel || [options.emotion || 'neutral'];
        requestBody.voice.__experimental_controls = {
          emotion: emotionLevel
        };
      }

      console.log(`üì§ [TTS] Request:`, JSON.stringify(requestBody, null, 2));

      // Helper function for fetch with timeout
      const fetchWithTimeout = async (url: string, options: RequestInit, timeoutMs: number = 15000) => {
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), timeoutMs);

        try {
          const response = await fetch(url, {
            ...options,
            signal: controller.signal
          });
          clearTimeout(timeoutId);
          return response;
        } catch (error: any) {
          if (error.name === 'AbortError') {
            throw new Error(`Request timeout after ${timeoutMs}ms`);
          }
          throw error;
        }
      };

      // Make request with timeout and timing
      const fetchStartTime = Date.now();
      console.log(`üì§ [TTS] Starting TTS request to Cartesia API...`);

      const response = await fetchWithTimeout("https://api.cartesia.ai/tts/bytes", {
        method: "POST",
        headers: {
          "X-API-Key": API_KEY,
          "Cartesia-Version": "2024-06-10",
          "Content-Type": "application/json"
        },
        body: JSON.stringify(requestBody)
      }, 15000); // 15 seconds timeout

      const fetchTime = Date.now() - fetchStartTime;
      console.log(`üì• [TTS] Fetch completed in ${fetchTime}ms`);
      console.log(`üì• [TTS] Response status: ${response.status}`);

      // Check response
      if (!response.ok) {
        const errorText = await response.text();
        console.error(`‚ùå [TTS] API Error (${response.status}):`, errorText);
        console.error(`‚ùå [TTS] Check API key, request format, and network connectivity`);

        return null;
      }

      // Get audio data with timing
      console.log(`‚úÖ [TTS] Response OK, reading audio...`);
      const arrayBufferStartTime = Date.now();
      const arrayBuffer = await response.arrayBuffer();
      const arrayBufferTime = Date.now() - arrayBufferStartTime;
      console.log(`‚úÖ [TTS] Audio received: ${arrayBuffer.byteLength} bytes (ArrayBuffer read in ${arrayBufferTime}ms)`);

      // Save to file
      const filename = `speech_${Date.now()}.mp3`;
      const filepath = `${FileSystem.cacheDirectory}${filename}`;

      const base64Audio = this.arrayBufferToBase64(arrayBuffer);

      const saveStartTime = Date.now();
      await FileSystem.writeAsStringAsync(filepath, base64Audio, {
        encoding: 'base64'
      });
      const saveTime = Date.now() - saveStartTime;

      console.log(`üíæ [TTS] Saved to: ${filepath} (File write in ${saveTime}ms)`);
      console.log(`‚è±Ô∏è [TTS] BREAKDOWN: Fetch=${fetchTime}ms, ArrayBuffer=${arrayBufferTime}ms, Save=${saveTime}ms, Total=${fetchTime + arrayBufferTime + saveTime}ms`);

      return filepath;

    } catch (error) {
      console.error("‚ùå [TTS] Fatal error:", error);
      if (error instanceof Error) {
        console.error("‚ùå [TTS] Error message:", error.message);
        console.error("‚ùå [TTS] Error stack:", error.stack);
      }
      return null;
    }
  }

  // ========================
  // STREAMING TTS METHODS (Phase 3)
  // ========================

  /**
   * Speak using Cartesia WebSocket streaming
   * 
   * NEW: Phase 3 - Streaming implementation
   * Uses WebSocket for real-time audio generation and chunked playback
   */
  private async speakCartesiaStreaming(
    text: string,
    options?: {
      emotion?: string;
      speed?: number;
      emotionLevel?: string[];
      autoPlay?: boolean;
    }
  ): Promise<boolean> {
    try {
      console.log('üåä [TTS Streaming] Starting WebSocket generation...');

      const VOICE_ID = process.env.EXPO_PUBLIC_CARTESIA_VOICE_ID || "e07c00bc-4134-4eae-9ea4-1a55fb45746b";

      // Stop any previous streaming playback
      if (this.isStreaming) {
        console.log('üõë [TTS Streaming] Stopping previous stream...');
        await chunkedStreamingPlayer.stop();
        this.isStreaming = false;
      }

      // Map speed number to Cartesia speed string
      let speedString: 'slowest' | 'slow' | 'normal' | 'fast' | 'fastest' = 'normal';
      if (options?.speed) {
        if (options.speed <= 0.75) speedString = 'slowest';
        else if (options.speed <= 0.9) speedString = 'slow';
        else if (options.speed >= 1.25) speedString = 'fastest';
        else if (options.speed >= 1.1) speedString = 'fast';
      }

      // Map emotion to Cartesia emotion array
      const emotionLevel = options?.emotionLevel || (options?.emotion ? [options.emotion] : undefined);

      console.log('üéôÔ∏è [TTS Streaming] Options:', {
        voiceId: VOICE_ID,
        speed: speedString,
        emotion: emotionLevel,
        textLength: text.length
      });

      // Create audio stream generator
      const chunkGenerator = cartesiaStreamingService.generateAudioStream({
        voiceId: VOICE_ID,
        text: text,
        emotion: emotionLevel,
        speed: speedString,
        onFirstChunk: (latency) => {
          console.log(`üéØ [TTS Streaming] First chunk in ${latency}ms`);
        },
        onError: (error) => {
          console.error('‚ùå [TTS Streaming] Generation error:', error);
        },
        onComplete: () => {
          console.log('‚úÖ [TTS Streaming] Generation complete');
        },
        // PHASE 2: Forward timestamps directly to player
        onTimestampsReceived: (timestamps) => {
          chunkedStreamingPlayer.receiveTimestamps(timestamps);
        }
      });

      // Play the stream with sentence chunking
      this.isStreaming = true;

      if (options?.autoPlay !== false) {
        await chunkedStreamingPlayer.playStream(chunkGenerator, {
          originalText: text,
          enableSentenceChunking: true
        });
        console.log('‚úÖ [TTS Streaming] Playback complete');
      }

      this.isStreaming = false;
      return true;

    } catch (error) {
      console.error('‚ùå [TTS Streaming] Error:', error);
      this.isStreaming = false;
      throw error;
    }
  }

  /**
   * Play audio file
   */
  private async playAudioFile(filepath: string, speed?: number): Promise<boolean> {
    try {
      const playbackRate = speed || 1.0;
      console.log(`üîä [TTS] Playing: ${filepath}`);
      console.log(`üîä [TTS] Playing at rate: ${playbackRate}`);

      const { sound } = await Audio.Sound.createAsync(
        { uri: filepath },
        {
          shouldPlay: true,
          volume: 1.0,
          rate: playbackRate,
          pitchCorrectionQuality: Audio.PitchCorrectionQuality.High
        }
      );

      this.soundObjects.push(sound);
      this.isPlaying = true;

      sound.setOnPlaybackStatusUpdate((status) => {
        if (status.isLoaded && status.didJustFinish) {
          console.log("‚úÖ [TTS] Playback finished");
          this.isPlaying = false;
        }
      });

      return true;

    } catch (error) {
      console.error("‚ùå [TTS] Playback error:", error);
      this.isPlaying = false;
      return false;
    }
  }

  /**
   * Convert ArrayBuffer to Base64 string
   */
  private arrayBufferToBase64(buffer: ArrayBuffer): string {
    const bytes = new Uint8Array(buffer);
    let binary = '';
    for (let i = 0; i < bytes.byteLength; i++) {
      binary += String.fromCharCode(bytes[i]);
    }
    return btoa(binary);
  }

  /**
   * Stop all audio playback (including streaming)
   * 
   * NEW: Also stops streaming playback if active
   */
  async stop(): Promise<void> {
    console.log("‚èπÔ∏è [TTS] Stopping all audio...");

    // NEW: Stop streaming if active
    if (this.isStreaming) {
      console.log("üõë [TTS] Stopping streaming playback...");
      try {
        await chunkedStreamingPlayer.stop();
        this.isStreaming = false;
      } catch (error) {
        console.error("‚ùå [TTS] Error stopping streaming:", error);
      }
    }

    // Stop regular playback
    for (const sound of this.soundObjects) {
      try {
        await sound.stopAsync();
        await sound.unloadAsync();
      } catch (error) {
        console.error("‚ùå [TTS] Stop error:", error);
      }
    }

    this.soundObjects = [];
    this.isPlaying = false;

    console.log("‚úÖ [TTS] All audio stopped");
  }

  /**
   * Preload audio and return a player object for manual control
   * This method is used by the interview logic for synchronized playback
   * 
   * NEW: Uses streaming if enabled (plays immediately, returns mock Sound)
   */
  async prepareAudio(
    text: string,
    options?: {
      emotion?: string;
      speed?: number;
      emotionLevel?: string[];
    }
  ): Promise<Audio.Sound | null> {
    // –ü–†–û–í–ï–†–ö–ê MUTE
    if (this.isMuted) {
      console.log(`üîá [TTS] Muted - skipping prepare: "${text.substring(0, 30)}..."`);
      return null;
    }

    try {
      console.log(`üéôÔ∏è [TTS] Preparing audio: "${text.substring(0, 50)}..."`);

      // NEW: Try streaming if enabled for Cartesia
      if (STREAMING_CONFIG.enabled && this.ttsProvider === 'cartesia') {
        console.log('üåä [TTS] Using streaming for prepareAudio...');

        try {
          // FIX: –ù–ï –∑–∞–ø—É—Å–∫–∞–µ–º streaming —Å—Ä–∞–∑—É, —Å–æ–∑–¥–∞–µ–º Promise –¥–ª—è –æ—Ç–ª–æ–∂–µ–Ω–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
          let streamingPromise: Promise<boolean> | null = null;
          let isPlaybackStarted = false;
          let statusCallback: ((status: any) => void) | null = null;

          const mockSound = {
            playAsync: async () => {
              console.log('üéµ [TTS Streaming Mock] playAsync called');

              // –ó–∞–ø—É—Å–∫–∞–µ–º streaming –¢–û–õ–¨–ö–û –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –≤—ã–∑–æ–≤–µ playAsync
              if (!isPlaybackStarted) {
                isPlaybackStarted = true;
                console.log('‚ñ∂Ô∏è [TTS Streaming Mock] Starting streaming playback...');

                try {
                  streamingPromise = this.speakCartesiaStreaming(text, {
                    ...options,
                    autoPlay: true
                  });

                  await streamingPromise;
                  console.log('‚úÖ [TTS Streaming Mock] Playback complete');

                  // FIX: –í—ã–∑—ã–≤–∞–µ–º callback –°–†–ê–ó–£ –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
                  if (statusCallback) {
                    console.log('üì¢ [TTS Streaming Mock] Triggering didJustFinish from playAsync');
                    statusCallback({
                      isLoaded: true,
                      didJustFinish: true,
                      durationMillis: 0,
                      positionMillis: 0
                    });
                  }
                } catch (error) {
                  console.error('‚ùå [TTS Streaming Mock] Playback error:', error);

                  // FIX: –í—ã–∑—ã–≤–∞–µ–º callback –¥–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è deadlock
                  if (statusCallback) {
                    console.log('üì¢ [TTS Streaming Mock] Triggering didJustFinish (error case)');
                    statusCallback({
                      isLoaded: true,
                      didJustFinish: true,
                      durationMillis: 0,
                      positionMillis: 0
                    });
                  }
                }
              } else {
                console.warn('‚ö†Ô∏è [TTS Streaming Mock] playAsync called multiple times, ignoring');
              }
            },

            setOnPlaybackStatusUpdate: (callback: any) => {
              console.log('üîÑ [TTS Streaming Mock] setOnPlaybackStatusUpdate called');

              // FIX: –ü—Ä–æ—Å—Ç–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º callback, –æ–Ω –±—É–¥–µ—Ç –≤—ã–∑–≤–∞–Ω –∏–∑ playAsync
              statusCallback = callback;
            },

            stopAsync: async () => {
              console.log('üõë [TTS Streaming Mock] Stop requested');
              await chunkedStreamingPlayer.stop();
              isPlaybackStarted = false;
              streamingPromise = null;
              statusCallback = null;
            },

            unloadAsync: async () => {
              console.log('üóëÔ∏è [TTS Streaming Mock] Unload');
              await chunkedStreamingPlayer.stop();
              isPlaybackStarted = false;
              streamingPromise = null;
              statusCallback = null;
            }
          } as any as Audio.Sound;

          console.log('‚úÖ [TTS] Streaming mock Sound created (playback deferred)');
          return mockSound;

        } catch (error) {
          console.error('‚ùå [TTS] Streaming failed in prepareAudio, falling back:', error);
          // Fall through to REST API
        }
      }

      // Standard (REST API) path
      const audioFile = await this.fetchAudioFile(text, options);

      if (!audioFile) {
        console.error("‚ùå [TTS] Failed to fetch audio");
        return null;
      }

      console.log(`üîä [TTS] Loading audio from: ${audioFile}`);

      const { sound } = await Audio.Sound.createAsync(
        { uri: audioFile },
        {
          shouldPlay: false,
          volume: 1.0,
          rate: options?.speed || 1.0,
          pitchCorrectionQuality: Audio.PitchCorrectionQuality.High
        }
      );

      this.soundObjects.push(sound);

      console.log("‚úÖ [TTS] Audio prepared successfully");
      return sound;

    } catch (error) {
      console.error("‚ùå [TTS] prepareAudio error:", error);
      return null;
    }
  }

  /**
   * Check if currently playing
   */
  getIsPlaying(): boolean {
    return this.isPlaying;
  }

  /**
   * Cleanup resources
   */
  async cleanup(): Promise<void> {
    await this.stop();
  }
}

export default new TTSService();