üöÄ –ü–ª–∞–Ω –≤–Ω–µ–¥—Ä–µ–Ω–∏—è Streaming TTS (Cartesia) - –í–ï–†–°–ò–Ø 2.0 (–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø)

üìã –ö—Ä–∏—Ç–∏—á–Ω—ã–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—Ç v1.0

‚úÖ –£–±—Ä–∞–Ω hardcoded API key ‚Üí –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ process.env
‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ —è–≤–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è memory limit
‚úÖ –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –æ–∂–∏–¥–∞–Ω–∏—è –¥–ª—è Progressive Loading (—Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç)
‚úÖ –î–µ—Ç–∞–ª—å–Ω—ã–π rollback –ø–ª–∞–Ω –µ—Å–ª–∏ PoC –ø—Ä–æ–≤–∞–ª–∏—Ç—Å—è
‚úÖ –ß–µ—Ç–∫–∏–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏ GO/NO-GO —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
‚úÖ –£–ª—É—á—à–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ WebSocket
‚úÖ –î–æ–±–∞–≤–ª–µ–Ω graceful degradation –ø—Ä–∏ —Å–µ—Ç–µ–≤—ã—Ö –ø—Ä–æ–±–ª–µ–º–∞—Ö

---

üéØ –§–∞–∑—ã —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

## –§–ê–ó–ê 0: PROOF OF CONCEPT ‚ö° (4-5 —á–∞—Å–æ–≤) - –ö–†–ò–¢–ò–ß–ù–û

**–¶–µ–ª—å:** –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å streaming —Å expo-av –ü–ï–†–ï–î –ø–æ–ª–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–µ–π.

**–í–ê–ñ–ù–û:** –ï—Å–ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –∫—Ä–∏—Ç–µ—Ä–∏–π –ø—Ä–æ–≤–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç—Å—è ‚Üí STOP, –Ω–µ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º.

---

### 0.1 –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π WebSocket –∫–ª–∏–µ–Ω—Ç (1.5 —á–∞—Å–∞)

**–ß—Ç–æ –¥–µ–ª–∞–µ–º:**

–°–æ–∑–¥–∞—Ç—å –ø—Ä–æ—Å—Ç–æ–π WebSocket –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Cartesia  
–û—Ç–ø—Ä–∞–≤–∏—Ç—å –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∫–æ—Ä–æ—Ç–∫–æ–π —Ñ—Ä–∞–∑—ã ("Hello world")  
–ü–æ–ª—É—á–∏—Ç—å audio chunks (base64 encoded PCM)  
–î–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å base64 ‚Üí ArrayBuffer  
–í—ã–≤–µ—Å—Ç–∏ –≤ –∫–æ–Ω—Å–æ–ª—å —Ä–∞–∑–º–µ—Ä—ã —á–∞–Ω–∫–æ–≤ –∏ timing

**–†–µ–∞–ª–∏–∑–∞—Ü–∏—è:**

```typescript
// src/poc/test-cartesia-websocket.ts

async function testCartesiaWebSocket() {
  const API_KEY = process.env.EXPO_PUBLIC_CARTESIA_API_KEY; // ‚úÖ –ù–ï HARDCODE
  const VOICE_ID = "e07c00bc-4134-4eae-9ea4-1a55fb45746b";
  const WS_URL = "wss://api.cartesia.ai/tts/websocket";
  
  console.log("üß™ [PoC] Starting WebSocket test...");
  
  const metrics = {
    connectionStart: Date.now(),
    connectionTime: 0,
    firstChunkTime: 0,
    totalChunks: 0,
    chunks: [] as { size: number, timestamp: number, sequence: number }[]
  };
  
  return new Promise((resolve, reject) => {
    const ws = new WebSocket(`${WS_URL}?api_key=${API_KEY}&cartesia_version=2024-06-10`);
    
    ws.onopen = () => {
      metrics.connectionTime = Date.now() - metrics.connectionStart;
      console.log(`‚úÖ [PoC] Connected in ${metrics.connectionTime}ms`);
      
      // Send generation request
      const request = {
        context_id: "poc-test-001",
        model_id: "sonic-3",
        transcript: "Hello world",
        voice: {
          mode: "id",
          id: VOICE_ID
        },
        output_format: {
          container: "raw",
          encoding: "pcm_s16le",
          sample_rate: 16000
        }
      };
      
      ws.send(JSON.stringify(request));
      console.log("üì§ [PoC] Request sent");
    };
    
    ws.onmessage = (event) => {
      try {
        const message = JSON.parse(event.data);
        
        if (message.type === 'chunk') {
          const chunkData = message.data; // base64 encoded PCM
          const arrayBuffer = base64ToArrayBuffer(chunkData);
          
          const chunk = {
            size: arrayBuffer.byteLength,
            timestamp: Date.now(),
            sequence: metrics.totalChunks
          };
          
          metrics.chunks.push(chunk);
          metrics.totalChunks++;
          
          if (metrics.totalChunks === 1) {
            metrics.firstChunkTime = chunk.timestamp - metrics.connectionStart;
            console.log(`üéØ [PoC] First chunk in ${metrics.firstChunkTime}ms`);
          }
          
          console.log(`üì¶ [PoC] Chunk #${chunk.sequence}: ${chunk.size} bytes at +${chunk.timestamp - metrics.connectionStart}ms`);
        }
        
        if (message.type === 'done') {
          console.log("‚úÖ [PoC] Generation complete");
          ws.close();
          resolve(metrics);
        }
        
      } catch (error) {
        console.error("‚ùå [PoC] Message parse error:", error);
      }
    };
    
    ws.onerror = (error) => {
      console.error("‚ùå [PoC] WebSocket error:", error);
      reject(error);
    };
    
    ws.onclose = () => {
      console.log("üîå [PoC] Connection closed");
    };
    
    // Timeout safety
    setTimeout(() => {
      if (ws.readyState !== WebSocket.CLOSED) {
        console.error("‚ùå [PoC] Timeout - closing connection");
        ws.close();
        reject(new Error("Timeout"));
      }
    }, 10000);
  });
}

function base64ToArrayBuffer(base64: string): ArrayBuffer {
  const binaryString = atob(base64);
  const bytes = new Uint8Array(binaryString.length);
  for (let i = 0; i < binaryString.length; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }
  return bytes.buffer;
}
```

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ —É—Å–ø–µ—Ö–∞:**

- ‚úÖ WebSocket —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è < 500ms
- ‚úÖ –ü–µ—Ä–≤—ã–π —á–∞–Ω–∫ –ø—Ä–∏—Ö–æ–¥–∏—Ç < 300ms –ø–æ—Å–ª–µ –æ—Ç–ø—Ä–∞–≤–∫–∏ –∑–∞–ø—Ä–æ—Å–∞
- ‚úÖ –ß–∞–Ω–∫–∏ –ø—Ä–∏—Ö–æ–¥—è—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ (–Ω–µ batch) - —Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É —á–∞–Ω–∫–∞–º–∏ < 100ms
- ‚úÖ –î–∞–Ω–Ω—ã–µ –¥–µ–∫–æ–¥–∏—Ä—É—é—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ (ArrayBuffer —Å PCM)
- ‚úÖ –ú–∏–Ω–∏–º—É–º 3 —á–∞–Ω–∫–∞ –ø–æ–ª—É—á–µ–Ω–æ (–æ–∑–Ω–∞—á–∞–µ—Ç –Ω–∞—Å—Ç–æ—è—â–∏–π streaming)

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–æ–≤–∞–ª–∞ (STOP):**

- ‚ùå WebSocket –Ω–µ –ø–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è –∑–∞ 500ms
- ‚ùå –í—Å–µ —á–∞–Ω–∫–∏ –ø—Ä–∏—Ö–æ–¥—è—Ç –æ–¥–Ω–∏–º –±–∞—Ç—á–µ–º (—Ä–∞–∑–Ω–∏—Ü–∞ < 10ms)
- ‚ùå –ó–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–≤–æ–≥–æ —á–∞–Ω–∫–∞ > 1000ms
- ‚ùå –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–¥–∞–µ—Ç —Å –æ—à–∏–±–∫–æ–π
- ‚ùå –ü–æ–ª—É—á–µ–Ω —Ç–æ–ª—å–∫–æ 1 —á–∞–Ω–∫ (–Ω–µ streaming)

---

### 0.2 PCM ‚Üí WAV –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è (1.5 —á–∞—Å–∞)

**–ß—Ç–æ –¥–µ–ª–∞–µ–º:**

–ù–∞–ø–∏—Å–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é convertPCMtoWAV(chunks: ArrayBuffer[])  
–°–æ–∑–¥–∞—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π WAV header (44 bytes)  
–û–±—ä–µ–¥–∏–Ω–∏—Ç—å header + –≤—Å–µ PCM chunks  
–ó–∞–ø–∏—Å–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–∞–π–ª —á–µ—Ä–µ–∑ FileSystem  
–ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ —á–µ—Ä–µ–∑ expo-av

**–†–µ–∞–ª–∏–∑–∞—Ü–∏—è:**

```typescript
// src/poc/test-wav-conversion.ts

function createWavHeader(
  sampleRate: number,
  numChannels: number,
  bitsPerSample: number,
  dataSize: number
): ArrayBuffer {
  const buffer = new ArrayBuffer(44);
  const view = new DataView(buffer);
  
  // RIFF header
  writeString(view, 0, 'RIFF');
  view.setUint32(4, 36 + dataSize, true); // File size - 8
  writeString(view, 8, 'WAVE');
  
  // fmt chunk
  writeString(view, 12, 'fmt ');
  view.setUint32(16, 16, true); // fmt chunk size
  view.setUint16(20, 1, true); // PCM format
  view.setUint16(22, numChannels, true);
  view.setUint32(24, sampleRate, true);
  view.setUint32(28, sampleRate * numChannels * (bitsPerSample / 8), true); // Byte rate
  view.setUint16(32, numChannels * (bitsPerSample / 8), true); // Block align
  view.setUint16(34, bitsPerSample, true);
  
  // data chunk
  writeString(view, 36, 'data');
  view.setUint32(40, dataSize, true);
  
  return buffer;
}

function writeString(view: DataView, offset: number, str: string) {
  for (let i = 0; i < str.length; i++) {
    view.setUint8(offset + i, str.charCodeAt(i));
  }
}

function mergeArrayBuffers(buffers: ArrayBuffer[]): ArrayBuffer {
  const totalLength = buffers.reduce((acc, buf) => acc + buf.byteLength, 0);
  const result = new Uint8Array(totalLength);
  let offset = 0;
  
  for (const buffer of buffers) {
    result.set(new Uint8Array(buffer), offset);
    offset += buffer.byteLength;
  }
  
  return result.buffer;
}

async function testWavConversion(pcmChunks: ArrayBuffer[]) {
  console.log("üß™ [PoC] Testing WAV conversion...");
  console.log(`üì¶ [PoC] Input: ${pcmChunks.length} PCM chunks`);
  
  const pcmData = mergeArrayBuffers(pcmChunks);
  const header = createWavHeader(16000, 1, 16, pcmData.byteLength);
  const wavFile = mergeArrayBuffers([header, pcmData]);
  
  console.log(`üì¶ [PoC] WAV file created: ${wavFile.byteLength} bytes`);
  
  // Save to file
  const filepath = `${FileSystem.cacheDirectory}poc_test.wav`;
  const base64 = arrayBufferToBase64(wavFile);
  
  await FileSystem.writeAsStringAsync(filepath, base64, {
    encoding: 'base64'
  });
  
  console.log(`üíæ [PoC] Saved to: ${filepath}`);
  
  // Try to play
  try {
    const { sound } = await Audio.Sound.createAsync(
      { uri: filepath },
      { shouldPlay: true }
    );
    
    console.log("‚úÖ [PoC] Playback started");
    
    // Wait for playback to finish
    return new Promise((resolve) => {
      sound.setOnPlaybackStatusUpdate((status) => {
        if (status.isLoaded && status.didJustFinish) {
          console.log("‚úÖ [PoC] Playback finished");
          sound.unloadAsync();
          resolve(true);
        }
      });
    });
    
  } catch (error) {
    console.error("‚ùå [PoC] Playback error:", error);
    throw error;
  }
}

function arrayBufferToBase64(buffer: ArrayBuffer): string {
  const bytes = new Uint8Array(buffer);
  let binary = '';
  for (let i = 0; i < bytes.byteLength; i++) {
    binary += String.fromCharCode(bytes[i]);
  }
  return btoa(binary);
}
```

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ —É—Å–ø–µ—Ö–∞:**

- ‚úÖ WAV —Ñ–∞–π–ª —Å–æ–∑–¥–∞–µ—Ç—Å—è –±–µ–∑ –æ—à–∏–±–æ–∫
- ‚úÖ expo-av –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç —Ñ–∞–π–ª
- ‚úÖ –ó–≤—É–∫ —á–∏—Å—Ç—ã–π, –±–µ–∑ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
- ‚úÖ –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–∂–∏–¥–∞–µ–º–æ–π (~1 —Å–µ–∫—É–Ω–¥–∞ –¥–ª—è "Hello world")
- ‚úÖ –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π (~32KB –¥–ª—è 1 —Å–µ–∫ @ 16kHz mono)

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–æ–≤–∞–ª–∞ (STOP):**

- ‚ùå WAV —Ñ–∞–π–ª –Ω–µ —Å–æ–∑–¥–∞–µ—Ç—Å—è
- ‚ùå expo-av –≤—ã–¥–∞–µ—Ç –æ—à–∏–±–∫—É –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ
- ‚ùå –°–ª—ã—à–Ω—ã –∏—Å–∫–∞–∂–µ–Ω–∏—è/—à—É–º—ã/—Ç—Ä–µ—Å–∫
- ‚ùå –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è (–≤ 2+ —Ä–∞–∑–∞ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è)
- ‚ùå –§–∞–π–ª –Ω–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è –≤–æ–æ–±—â–µ

---

### 0.3 Progressive File Writing —Ç–µ—Å—Ç (1.5 —á–∞—Å–∞)

**–í–ê–ñ–ù–û:** –°–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –ù–ï –°–†–ê–ë–û–¢–ê–ï–¢ —Å expo-av. –≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ - –ø—Ä–æ–¥–æ–ª–∂–∏–º —Å Chunked Files.

**–ß—Ç–æ –¥–µ–ª–∞–µ–º:**

–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –º–æ–∂–µ—Ç –ª–∏ expo-av –∏–≥—Ä–∞—Ç—å —á–∞—Å—Ç–∏—á–Ω–æ –∑–∞–ø–∏—Å–∞–Ω–Ω—ã–π WAV —Ñ–∞–π–ª  
–°—Ç—Ä–∞—Ç–µ–≥–∏—è: –∑–∞–ø–∏—Å–∞—Ç—å header + –ø–µ—Ä–≤—ã–µ 200ms PCM ‚Üí –Ω–∞—á–∞—Ç—å play ‚Üí –¥–æ–ø–∏—Å—ã–≤–∞—Ç—å chunks

**–†–µ–∞–ª–∏–∑–∞—Ü–∏—è:**

```typescript
// src/poc/test-progressive-loading.ts

async function testProgressiveLoading(pcmChunks: ArrayBuffer[]) {
  console.log("üß™ [PoC] Testing progressive file loading...");
  
  // –†–∞–∑–¥–µ–ª–∏–º —á–∞–Ω–∫–∏: –ø–µ—Ä–≤—ã–µ 20% –¥–ª—è –Ω–∞—á–∞–ª–∞, –æ—Å—Ç–∞–ª—å–Ω—ã–µ –¥–æ–ø–∏—Å—ã–≤–∞–µ–º
  const initialChunks = pcmChunks.slice(0, Math.ceil(pcmChunks.length * 0.2));
  const remainingChunks = pcmChunks.slice(initialChunks.length);
  
  console.log(`üì¶ [PoC] Initial: ${initialChunks.length}, Remaining: ${remainingChunks.length}`);
  
  const filepath = `${FileSystem.cacheDirectory}poc_progressive.wav`;
  
  // 1. –°–æ–∑–¥–∞—Ç—å WAV —Å placeholder size (–±–æ–ª—å—à–æ–π)
  const totalDataSize = pcmChunks.reduce((sum, c) => sum + c.byteLength, 0);
  const header = createWavHeader(16000, 1, 16, totalDataSize);
  
  // 2. –ó–∞–ø–∏—Å–∞—Ç—å header + initial chunks
  const initialPcm = mergeArrayBuffers(initialChunks);
  const initialWav = mergeArrayBuffers([header, initialPcm]);
  const base64Initial = arrayBufferToBase64(initialWav);
  
  await FileSystem.writeAsStringAsync(filepath, base64Initial, {
    encoding: 'base64'
  });
  
  console.log(`üíæ [PoC] Initial file written: ${initialWav.byteLength} bytes`);
  
  // 3. –ù–∞—á–∞—Ç—å playback
  let sound: Audio.Sound;
  try {
    const result = await Audio.Sound.createAsync(
      { uri: filepath },
      { shouldPlay: true }
    );
    sound = result.sound;
    console.log("‚úÖ [PoC] Playback started");
  } catch (error) {
    console.error("‚ùå [PoC] Failed to start playback:", error);
    throw error;
  }
  
  // 4. –î–æ–ø–∏—Å—ã–≤–∞—Ç—å chunks –≤–æ –≤—Ä–µ–º—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
  let progressiveWorked = false;
  
  for (let i = 0; i < remainingChunks.length; i++) {
    await new Promise(resolve => setTimeout(resolve, 100)); // 100ms –º–µ–∂–¥—É —á–∞–Ω–∫–∞–º–∏
    
    // –ß–∏—Ç–∞–µ–º —Ç–µ–∫—É—â–∏–π —Ñ–∞–π–ª
    const currentBase64 = await FileSystem.readAsStringAsync(filepath, {
      encoding: 'base64'
    });
    const currentBuffer = base64ToArrayBuffer(currentBase64);
    
    // –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π —á–∞–Ω–∫
    const newBuffer = mergeArrayBuffers([currentBuffer, remainingChunks[i]]);
    const newBase64 = arrayBufferToBase64(newBuffer);
    
    await FileSystem.writeAsStringAsync(filepath, newBase64, {
      encoding: 'base64'
    });
    
    console.log(`üìù [PoC] Appended chunk ${i + 1}/${remainingChunks.length}`);
    
    // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å playback
    const status = await sound.getStatusAsync();
    if (status.isLoaded) {
      const position = status.positionMillis;
      const duration = status.durationMillis || 0;
      console.log(`üéµ [PoC] Position: ${position}ms / Duration: ${duration}ms`);
      
      // –ï—Å–ª–∏ duration —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è - progressive loading —Ä–∞–±–æ—Ç–∞–µ—Ç!
      if (duration > initialChunks.length * 100) {
        progressiveWorked = true;
      }
    }
  }
  
  // 5. –î–æ–∂–¥–∞—Ç—å—Å—è –æ–∫–æ–Ω—á–∞–Ω–∏—è
  await new Promise((resolve) => {
    sound.setOnPlaybackStatusUpdate((status) => {
      if (status.isLoaded && status.didJustFinish) {
        console.log("‚úÖ [PoC] Playback finished");
        sound.unloadAsync();
        resolve(true);
      }
    });
  });
  
  return {
    progressiveWorked,
    recommendation: progressiveWorked ? 'hybrid' : 'chunked'
  };
}
```

**–°—Ü–µ–Ω–∞—Ä–∏–∏:**

**–°—Ü–µ–Ω–∞—Ä–∏–π A: Progressive loading —Ä–∞–±–æ—Ç–∞–µ—Ç (–º–∞–ª–æ–≤–µ—Ä–æ—è—Ç–Ω–æ)**

- Sound object –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–¥—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
- Duration —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è –≤–æ –≤—Ä–µ–º—è playback
- –í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ
- ‚Üí –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Hybrid Buffering —Å—Ç—Ä–∞—Ç–µ–≥–∏—é

**–°—Ü–µ–Ω–∞—Ä–∏–π B: Progressive loading –ù–ï —Ä–∞–±–æ—Ç–∞–µ—Ç (–æ–∂–∏–¥–∞–µ–º–æ)**

- Sound object –∏–≥—Ä–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Ç–æ —á—Ç–æ –±—ã–ª–æ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏
- Duration –æ—Å—Ç–∞–µ—Ç—Å—è —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º
- –ù–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–≥–Ω–æ—Ä–∏—Ä—É—é—Ç—Å—è
- ‚Üí –ù—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Chunked Files —Å—Ç—Ä–∞—Ç–µ–≥–∏—é (–Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω–∏-—Ñ–∞–π–ª–æ–≤)

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ —É—Å–ø–µ—Ö–∞:**

- ‚úÖ –û–ø—Ä–µ–¥–µ–ª–∏–ª–∏ —Ä–∞–±–æ—Ç–∞–µ—Ç –ª–∏ progressive loading
- ‚úÖ –í—ã–±—Ä–∞–ª–∏ —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é (Hybrid –∏–ª–∏ Chunked)
- ‚úÖ Playback –Ω–µ –ø—Ä–µ—Ä—ã–≤–∞–µ—Ç—Å—è –≤–æ –≤—Ä–µ–º—è —Ç–µ—Å—Ç–∞

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–æ–≤–∞–ª–∞ (–ù–ï –∫—Ä–∏—Ç–∏—á–Ω–æ):**

- ‚ö†Ô∏è Progressive loading –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç ‚Üí –ø—Ä–æ—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º Chunked strategy
- ‚ùå Playback –ø–∞–¥–∞–µ—Ç —Å –æ—à–∏–±–∫–æ–π ‚Üí –ö–†–ò–¢–ò–ß–ù–û, STOP

---

### 0.4 PoC Decision Point (30 –º–∏–Ω)

**–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:**

–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ 0.1-0.3  
–°—Ä–∞–≤–Ω–∏—Ç—å —Å —Ü–µ–ª–µ–≤—ã–º–∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è–º–∏

**–†–µ—à–µ–Ω–∏—è:**

**–ï—Å–ª–∏ –≤—Å–µ —Ç–µ—Å—Ç—ã —É—Å–ø–µ—à–Ω—ã (GO):**

- ‚úÖ –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –§–ê–ó–û–ô 1 (Full Implementation)
- ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—ã–±—Ä–∞–Ω–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é (Hybrid –∏–ª–∏ Chunked)
- ‚úÖ –û–∂–∏–¥–∞–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ: ~2500ms ‚Üí ~300ms (8x faster!)
- ‚úÖ –°–æ–∑–¥–∞—Ç—å environment variable: `CARTESIA_STREAMING_ENABLED=true`
- ‚úÖ –°–æ–∑–¥–∞—Ç—å environment variable: `CARTESIA_STREAMING_STRATEGY=chunked` (–∏–ª–∏ hybrid)

**–ï—Å–ª–∏ –µ—Å—Ç—å –∫—Ä–∏—Ç–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã (NO-GO):**

- ‚ö†Ô∏è –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—É: react-native-audio-toolkit
- ‚ö†Ô∏è –ò–ª–∏ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –¥—Ä—É–≥–æ–π TTS provider —Å –ª—É—á—à–∏–º SDK
- ‚ö†Ô∏è –ò–ª–∏ –æ—Å—Ç–∞—Ç—å—Å—è –Ω–∞ REST API —Å –¥—Ä—É–≥–∏–º–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏:
  - HTTP/2 multiplexing
  - –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
  - –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∞—Å—Ç—ã—Ö —Ñ—Ä–∞–∑
  - Pre-generation –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –≤–æ–ø—Ä–æ—Å–æ–≤
- ‚ö†Ô∏è –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏—á–∏–Ω—ã –æ—Ç–∫–∞–∑–∞ –æ—Ç streaming

**Deliverables PoC:**

–°–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª: `docs/streaming-tts-poc-report.md`

```markdown
# Streaming TTS PoC Report

Date: YYYY-MM-DD
Duration: X hours

## Results

### WebSocket Test (0.1)
- Connection time: XXXms ‚úÖ/‚ùå
- First chunk latency: XXXms ‚úÖ/‚ùå
- Chunks received: X ‚úÖ/‚ùå
- Streaming mode: true/false ‚úÖ/‚ùå

### WAV Conversion Test (0.2)
- Conversion: success/fail ‚úÖ/‚ùå
- Playback: success/fail ‚úÖ/‚ùå
- Audio quality: good/bad ‚úÖ/‚ùå

### Progressive Loading Test (0.3)
- Progressive loading: works/doesn't work ‚ö†Ô∏è
- Recommended strategy: hybrid/chunked

## Decision

GO / NO-GO

Rationale: ...

## Next Steps

If GO:
- Proceed to Phase 1
- Use [hybrid/chunked] strategy
- Expected improvement: XXXms ‚Üí XXXms

If NO-GO:
- Alternative approach: ...
- Reason: ...
```

---

## –§–ê–ó–ê 1: –ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∏ Types (1.5 —á–∞—Å–∞)

**–¢–û–õ–¨–ö–û –ï–°–õ–ò PoC = GO**

### 1.1 –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ (30 –º–∏–Ω)

**–§–∞–π–ª:** `src/types.ts`

```typescript
// ========================
// STREAMING TTS TYPES
// ========================

export interface AudioChunk {
  data: ArrayBuffer;        // PCM audio data
  timestamp: number;        // –ö–æ–≥–¥–∞ –ø–æ–ª—É—á–µ–Ω (Date.now())
  sequence: number;         // –ü–æ—Ä—è–¥–∫–æ–≤—ã–π –Ω–æ–º–µ—Ä (0, 1, 2, ...)
  sizeBytes: number;        // –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞
}

export type StreamingPlayerState = 
  | 'idle'        // –ù–µ –∞–∫—Ç–∏–≤–µ–Ω
  | 'connecting'  // –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ WebSocket
  | 'buffering'   // –ù–∞–∫–æ–ø–ª–µ–Ω–∏–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –±—É—Ñ–µ—Ä–∞
  | 'playing'     // –í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ
  | 'completed'   // –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞
  | 'error';      // –û—à–∏–±–∫–∞

export interface StreamingPlayerConfig {
  minBufferMs: number;      // –ú–∏–Ω–∏–º—É–º –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º (200ms)
  targetBufferMs: number;   // –¶–µ–ª–µ–≤–æ–π –±—É—Ñ–µ—Ä (1000ms)
  chunkSampleRate: number;  // –ß–∞—Å—Ç–æ—Ç–∞ (16000Hz)
  maxRetries: number;       // –ü–æ–ø—ã—Ç–∫–∏ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è (3)
  strategy: 'hybrid' | 'chunked';  // –ò–∑ PoC
}

export interface CartesiaStreamingOptions {
  voiceId: string;
  text: string;
  emotion?: string[];
  speed?: 'slowest' | 'slow' | 'normal' | 'fast' | 'fastest';
  
  // Callbacks
  onChunk?: (chunk: AudioChunk) => void;
  onComplete?: () => void;
  onError?: (error: Error) => void;
  onFirstChunk?: (latency: number) => void;
}

export interface StreamingMetrics {
  generationStart: number;    // Timestamp –Ω–∞—á–∞–ª–∞
  firstChunkTime: number | null;  // Timestamp –ø–µ—Ä–≤–æ–≥–æ —á–∞–Ω–∫–∞
  firstPlayTime: number | null;   // Timestamp –Ω–∞—á–∞–ª–∞ playback
  totalChunks: number;        // –í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤
  totalBytes: number;         // –í—Å–µ–≥–æ –±–∞–π—Ç
  bufferUnderruns: number;    // –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ underruns
  averageChunkSize: number;   // –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞
  
  // Calculated
  get timeToFirstChunk(): number | null;
  get timeToFirstPlay(): number | null;
  get totalLatency(): number | null;
}
```

### 1.2 Environment Variables (15 –º–∏–Ω)

**–§–∞–π–ª:** `.env`

```bash
# Existing
EXPO_PUBLIC_CARTESIA_API_KEY=your_key_here
EXPO_PUBLIC_OPENAI_API_KEY=your_key_here

# NEW: Streaming TTS Configuration
EXPO_PUBLIC_CARTESIA_WS_URL=wss://api.cartesia.ai/tts/websocket
EXPO_PUBLIC_CARTESIA_STREAMING_ENABLED=true
EXPO_PUBLIC_CARTESIA_STREAMING_MIN_BUFFER_MS=200
EXPO_PUBLIC_CARTESIA_STREAMING_TARGET_BUFFER_MS=1000
EXPO_PUBLIC_CARTESIA_STREAMING_STRATEGY=chunked
EXPO_PUBLIC_CARTESIA_WS_PING_INTERVAL_MS=30000
EXPO_PUBLIC_CARTESIA_WS_RECONNECT_MAX_RETRIES=3
EXPO_PUBLIC_CARTESIA_WS_RECONNECT_BACKOFF_MS=1000
```

**Validation –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ:**

```typescript
// src/config/streaming-config.ts

export const STREAMING_CONFIG = {
  enabled: process.env.EXPO_PUBLIC_CARTESIA_STREAMING_ENABLED === 'true',
  wsUrl: process.env.EXPO_PUBLIC_CARTESIA_WS_URL || 'wss://api.cartesia.ai/tts/websocket',
  minBufferMs: parseInt(process.env.EXPO_PUBLIC_CARTESIA_STREAMING_MIN_BUFFER_MS || '200'),
  targetBufferMs: parseInt(process.env.EXPO_PUBLIC_CARTESIA_STREAMING_TARGET_BUFFER_MS || '1000'),
  strategy: (process.env.EXPO_PUBLIC_CARTESIA_STREAMING_STRATEGY || 'chunked') as 'hybrid' | 'chunked',
  pingIntervalMs: parseInt(process.env.EXPO_PUBLIC_CARTESIA_WS_PING_INTERVAL_MS || '30000'),
  maxRetries: parseInt(process.env.EXPO_PUBLIC_CARTESIA_WS_RECONNECT_MAX_RETRIES || '3'),
  reconnectBackoffMs: parseInt(process.env.EXPO_PUBLIC_CARTESIA_WS_RECONNECT_BACKOFF_MS || '1000'),
};

// Validation
if (STREAMING_CONFIG.enabled) {
  if (!process.env.EXPO_PUBLIC_CARTESIA_API_KEY) {
    throw new Error('EXPO_PUBLIC_CARTESIA_API_KEY required for streaming');
  }
  if (STREAMING_CONFIG.minBufferMs < 100 || STREAMING_CONFIG.minBufferMs > 2000) {
    console.warn(`‚ö†Ô∏è minBufferMs out of range: ${STREAMING_CONFIG.minBufferMs}ms`);
  }
  console.log('‚úÖ Streaming TTS config loaded:', STREAMING_CONFIG);
}
```

### 1.3 Utilities (45 –º–∏–Ω)

**–ù–æ–≤—ã–π —Ñ–∞–π–ª:** `src/utils/audio-conversion.ts`

```typescript
/**
 * Audio conversion utilities for streaming TTS
 */

/**
 * Convert base64 string to ArrayBuffer
 */
export function base64ToArrayBuffer(base64: string): ArrayBuffer {
  const binaryString = atob(base64);
  const bytes = new Uint8Array(binaryString.length);
  for (let i = 0; i < binaryString.length; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }
  return bytes.buffer;
}

/**
 * Convert ArrayBuffer to base64 string
 */
export function arrayBufferToBase64(buffer: ArrayBuffer): string {
  const bytes = new Uint8Array(buffer);
  let binary = '';
  for (let i = 0; i < bytes.byteLength; i++) {
    binary += String.fromCharCode(bytes[i]);
  }
  return btoa(binary);
}

/**
 * Create WAV file header
 */
export function createWavHeader(
  sampleRate: number,
  numChannels: number,
  bitsPerSample: number,
  dataSize: number
): ArrayBuffer {
  const buffer = new ArrayBuffer(44);
  const view = new DataView(buffer);
  
  // Helper to write string
  const writeString = (offset: number, str: string) => {
    for (let i = 0; i < str.length; i++) {
      view.setUint8(offset + i, str.charCodeAt(i));
    }
  };
  
  // RIFF header
  writeString(0, 'RIFF');
  view.setUint32(4, 36 + dataSize, true); // File size - 8
  writeString(8, 'WAVE');
  
  // fmt chunk
  writeString(12, 'fmt ');
  view.setUint32(16, 16, true); // fmt chunk size
  view.setUint16(20, 1, true); // PCM format
  view.setUint16(22, numChannels, true);
  view.setUint32(24, sampleRate, true);
  view.setUint32(28, sampleRate * numChannels * (bitsPerSample / 8), true); // Byte rate
  view.setUint16(32, numChannels * (bitsPerSample / 8), true); // Block align
  view.setUint16(34, bitsPerSample, true);
  
  // data chunk
  writeString(36, 'data');
  view.setUint32(40, dataSize, true);
  
  return buffer;
}

/**
 * Merge multiple ArrayBuffers into one
 */
export function mergePCMChunks(chunks: ArrayBuffer[]): ArrayBuffer {
  const totalLength = chunks.reduce((acc, chunk) => acc + chunk.byteLength, 0);
  const result = new Uint8Array(totalLength);
  let offset = 0;
  
  for (const chunk of chunks) {
    result.set(new Uint8Array(chunk), offset);
    offset += chunk.byteLength;
  }
  
  return result.buffer;
}

/**
 * Create complete WAV file from PCM chunks
 */
export function createWavFile(
  pcmChunks: ArrayBuffer[],
  sampleRate: number = 16000,
  numChannels: number = 1,
  bitsPerSample: number = 16
): ArrayBuffer {
  const pcmData = mergePCMChunks(pcmChunks);
  const header = createWavHeader(sampleRate, numChannels, bitsPerSample, pcmData.byteLength);
  
  return mergePCMChunks([header, pcmData]);
}

/**
 * Calculate audio duration from PCM data size
 */
export function calculateAudioDuration(
  dataSize: number,
  sampleRate: number = 16000,
  numChannels: number = 1,
  bitsPerSample: number = 16
): number {
  const bytesPerSample = bitsPerSample / 8;
  const totalSamples = dataSize / (numChannels * bytesPerSample);
  const durationSeconds = totalSamples / sampleRate;
  return durationSeconds * 1000; // Return in milliseconds
}

/**
 * Update WAV header with correct data size
 * (For progressive file writing)
 */
export function updateWavHeaderSize(
  wavBuffer: ArrayBuffer,
  newDataSize: number
): ArrayBuffer {
  const view = new DataView(wavBuffer);
  
  // Update file size at offset 4
  view.setUint32(4, 36 + newDataSize, true);
  
  // Update data chunk size at offset 40
  view.setUint32(40, newDataSize, true);
  
  return wavBuffer;
}
```

---

## –§–ê–ó–ê 2: Cartesia WebSocket Service (3 —á–∞—Å–∞)

### 2.1 –û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å (1.5 —á–∞—Å–∞)

**–ù–æ–≤—ã–π —Ñ–∞–π–ª:** `src/services/cartesia-streaming-service.ts`

```typescript
import { STREAMING_CONFIG } from '../config/streaming-config';
import { AudioChunk, CartesiaStreamingOptions } from '../types';
import { base64ToArrayBuffer } from '../utils/audio-conversion';

/**
 * Cartesia WebSocket streaming service
 */
class CartesiaStreamingService {
  private ws: WebSocket | null = null;
  private isConnectedFlag: boolean = false;
  private reconnectAttempts: number = 0;
  private currentContextId: string | null = null;
  private pingInterval: NodeJS.Timeout | null = null;
  private messageHandlers: Map<string, (message: any) => void> = new Map();
  
  private readonly apiKey: string;
  private readonly wsUrl: string;
  private readonly maxRetries: number;
  private readonly reconnectBackoffMs: number;
  private readonly pingIntervalMs: number;
  
  constructor() {
    this.apiKey = process.env.EXPO_PUBLIC_CARTESIA_API_KEY || '';
    this.wsUrl = STREAMING_CONFIG.wsUrl;
    this.maxRetries = STREAMING_CONFIG.maxRetries;
    this.reconnectBackoffMs = STREAMING_CONFIG.reconnectBackoffMs;
    this.pingIntervalMs = STREAMING_CONFIG.pingIntervalMs;
    
    if (!this.apiKey) {
      console.error('‚ùå [Cartesia WS] API key not configured');
    }
  }
  
  // ========================
  // CONNECTION MANAGEMENT
  // ========================
  
  /**
   * Connect to WebSocket
   */
  async connect(): Promise<void> {
    if (this.isConnectedFlag) {
      console.log('‚ÑπÔ∏è [Cartesia WS] Already connected');
      return;
    }
    
    return new Promise((resolve, reject) => {
      try {
        console.log('üîå [Cartesia WS] Connecting...');
        const url = `${this.wsUrl}?api_key=${this.apiKey}&cartesia_version=2024-06-10`;
        
        this.ws = new WebSocket(url);
        
        this.ws.onopen = () => {
          console.log('‚úÖ [Cartesia WS] Connected');
          this.isConnectedFlag = true;
          this.reconnectAttempts = 0;
          this.startPingInterval();
          resolve();
        };
        
        this.ws.onerror = (error) => {
          console.error('‚ùå [Cartesia WS] Error:', error);
          if (!this.isConnectedFlag) {
            reject(error);
          }
        };
        
        this.ws.onclose = (event) => {
          console.log(`üîå [Cartesia WS] Closed: ${event.code} ${event.reason}`);
          this.isConnectedFlag = false;
          this.stopPingInterval();
          
          // Auto-reconnect if unexpected close
          if (event.code !== 1000 && this.reconnectAttempts < this.maxRetries) {
            this.handleReconnect();
          }
        };
        
        this.ws.onmessage = (event) => {
          this.handleMessage(event.data);
        };
        
        // Connection timeout
        setTimeout(() => {
          if (!this.isConnectedFlag) {
            console.error('‚ùå [Cartesia WS] Connection timeout');
            this.ws?.close();
            reject(new Error('Connection timeout'));
          }
        }, 10000);
        
      } catch (error) {
        console.error('‚ùå [Cartesia WS] Connect error:', error);
        reject(error);
      }
    });
  }
  
  /**
   * Disconnect from WebSocket
   */
  disconnect(): void {
    console.log('üîå [Cartesia WS] Disconnecting...');
    this.stopPingInterval();
    this.messageHandlers.clear();
    this.currentContextId = null;
    
    if (this.ws) {
      this.ws.close(1000, 'Normal closure');
      this.ws = null;
    }
    
    this.isConnectedFlag = false;
  }
  
  /**
   * Check if connected
   */
  isConnected(): boolean {
    return this.isConnectedFlag && this.ws?.readyState === WebSocket.OPEN;
  }
  
  /**
   * Get connection state
   */
  getConnectionState(): 'connecting' | 'connected' | 'disconnected' | 'error' {
    if (!this.ws) return 'disconnected';
    
    switch (this.ws.readyState) {
      case WebSocket.CONNECTING:
        return 'connecting';
      case WebSocket.OPEN:
        return 'connected';
      case WebSocket.CLOSING:
      case WebSocket.CLOSED:
        return 'disconnected';
      default:
        return 'error';
    }
  }
  
  // ========================
  // AUDIO GENERATION
  // ========================
  
  /**
   * Generate audio stream (AsyncGenerator)
   */
  async* generateAudioStream(
    options: CartesiaStreamingOptions
  ): AsyncGenerator<AudioChunk, void, unknown> {
    if (!this.isConnected()) {
      await this.connect();
    }
    
    const contextId = `stream-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
    this.currentContextId = contextId;
    
    console.log(`üéôÔ∏è [Cartesia WS] Starting generation: "${options.text.substring(0, 50)}..."`);
    console.log(`üÜî [Cartesia WS] Context ID: ${contextId}`);
    
    // Create chunk queue
    const chunkQueue: AudioChunk[] = [];
    let isGenerating = true;
    let generationError: Error | null = null;
    let chunkSequence = 0;
    
    // Message handler for this context
    const handler = (message: any) => {
      if (message.context_id !== contextId) return;
      
      if (message.type === 'chunk' && message.data) {
        const arrayBuffer = base64ToArrayBuffer(message.data);
        const chunk: AudioChunk = {
          data: arrayBuffer,
          timestamp: Date.now(),
          sequence: chunkSequence++,
          sizeBytes: arrayBuffer.byteLength
        };
        
        chunkQueue.push(chunk);
        
        if (options.onChunk) {
          options.onChunk(chunk);
        }
        
        if (chunk.sequence === 0 && options.onFirstChunk) {
          const latency = Date.now() - generationStart;
          options.onFirstChunk(latency);
        }
      }
      
      if (message.type === 'done') {
        console.log('‚úÖ [Cartesia WS] Generation complete');
        isGenerating = false;
        
        if (options.onComplete) {
          options.onComplete();
        }
      }
      
      if (message.type === 'error') {
        console.error('‚ùå [Cartesia WS] Generation error:', message.error);
        generationError = new Error(message.error);
        isGenerating = false;
        
        if (options.onError) {
          options.onError(generationError);
        }
      }
    };
    
    this.messageHandlers.set(contextId, handler);
    
    // Send generation request
    const request = {
      context_id: contextId,
      model_id: 'sonic-3',
      transcript: options.text,
      voice: {
        mode: 'id',
        id: options.voiceId
      },
      output_format: {
        container: 'raw',
        encoding: 'pcm_s16le',
        sample_rate: 16000
      },
      ...(options.emotion && {
        voice: {
          mode: 'id',
          id: options.voiceId,
          __experimental_controls: {
            emotion: options.emotion
          }
        }
      }),
      ...(options.speed && {
        speed: options.speed
      })
    };
    
    const generationStart = Date.now();
    this.ws?.send(JSON.stringify(request));
    
    // Yield chunks as they arrive
    try {
      while (isGenerating || chunkQueue.length > 0) {
        if (chunkQueue.length > 0) {
          yield chunkQueue.shift()!;
        } else {
          // Wait for next chunk
          await new Promise(resolve => setTimeout(resolve, 10));
        }
        
        if (generationError) {
          throw generationError;
        }
      }
    } finally {
      // Cleanup
      this.messageHandlers.delete(contextId);
      if (this.currentContextId === contextId) {
        this.currentContextId = null;
      }
    }
  }
  
  /**
   * Cancel ongoing generation
   */
  cancelGeneration(): void {
    if (!this.currentContextId) {
      console.log('‚ÑπÔ∏è [Cartesia WS] No active generation to cancel');
      return;
    }
    
    console.log(`‚èπÔ∏è [Cartesia WS] Cancelling: ${this.currentContextId}`);
    
    // Send cancel request
    this.ws?.send(JSON.stringify({
      context_id: this.currentContextId,
      cancel: true
    }));
    
    // Cleanup
    this.messageHandlers.delete(this.currentContextId);
    this.currentContextId = null;
  }
  
  // ========================
  // PRIVATE METHODS
  // ========================
  
  /**
   * Handle incoming WebSocket message
   */
  private handleMessage(data: string): void {
    try {
      const message = JSON.parse(data);
      
      // Route to appropriate handler
      if (message.context_id && this.messageHandlers.has(message.context_id)) {
        const handler = this.messageHandlers.get(message.context_id)!;
        handler(message);
      }
      
      // Handle global messages
      if (message.type === 'pong') {
        // Pong received, connection alive
      }
      
    } catch (error) {
      console.error('‚ùå [Cartesia WS] Message parse error:', error);
    }
  }
  
  /**
   * Start ping interval for keepalive
   */
  private startPingInterval(): void {
    this.stopPingInterval();
    
    this.pingInterval = setInterval(() => {
      if (this.isConnected()) {
        this.ping();
      }
    }, this.pingIntervalMs);
  }
  
  /**
   * Stop ping interval
   */
  private stopPingInterval(): void {
    if (this.pingInterval) {
      clearInterval(this.pingInterval);
      this.pingInterval = null;
    }
  }
  
  /**
   * Send ping
   */
  private ping(): void {
    if (!this.isConnected()) return;
    
    this.ws?.send(JSON.stringify({ type: 'ping' }));
    
    // Set pong timeout
    setTimeout(() => {
      if (!this.isConnected()) {
        console.error('‚ùå [Cartesia WS] Ping timeout - reconnecting');
        this.handleReconnect();
      }
    }, 5000);
  }
  
  /**
   * Handle reconnection with exponential backoff
   */
  private async handleReconnect(): Promise<void> {
    if (this.reconnectAttempts >= this.maxRetries) {
      console.error('‚ùå [Cartesia WS] Max reconnect attempts reached');
      return;
    }
    
    this.reconnectAttempts++;
    const backoff = Math.min(
      this.reconnectBackoffMs * Math.pow(2, this.reconnectAttempts - 1),
      30000
    );
    
    console.log(`üîÑ [Cartesia WS] Reconnecting in ${backoff}ms (attempt ${this.reconnectAttempts}/${this.maxRetries})`);
    
    await new Promise(resolve => setTimeout(resolve, backoff));
    
    try {
      await this.connect();
      console.log('‚úÖ [Cartesia WS] Reconnected successfully');
    } catch (error) {
      console.error('‚ùå [Cartesia WS] Reconnect failed:', error);
      this.handleReconnect();
    }
  }
}

export default new CartesiaStreamingService();
```

### 2.2 Memory Management & Backpressure (30 –º–∏–Ω)

**–°—Ç—Ä–∞—Ç–µ–≥–∏—è –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ –ª–∏–º–∏—Ç–∞:**

```typescript
// Inside CartesiaStreamingService

private readonly MAX_BUFFER_SIZE_BYTES = 10 * 1024 * 1024; // 10MB
private currentBufferSize = 0;

// In generateAudioStream handler:
const handler = (message: any) => {
  if (message.type === 'chunk' && message.data) {
    const arrayBuffer = base64ToArrayBuffer(message.data);
    
    // Check buffer size
    if (this.currentBufferSize + arrayBuffer.byteLength > this.MAX_BUFFER_SIZE_BYTES) {
      console.warn(`‚ö†Ô∏è [Cartesia WS] Buffer limit reached (${this.currentBufferSize} bytes)`);
      
      // Strategy 1: Drop oldest chunks (–¥–ª—è real-time priority)
      while (chunkQueue.length > 0 && this.currentBufferSize > this.MAX_BUFFER_SIZE_BYTES / 2) {
        const dropped = chunkQueue.shift()!;
        this.currentBufferSize -= dropped.sizeBytes;
        console.warn(`‚ö†Ô∏è [Cartesia WS] Dropped chunk #${dropped.sequence}`);
      }
      
      // Strategy 2: Pause WebSocket (–¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞ priority)
      // this.ws?.send(JSON.stringify({ context_id: contextId, pause: true }));
    }
    
    const chunk: AudioChunk = {
      data: arrayBuffer,
      timestamp: Date.now(),
      sequence: chunkSequence++,
      sizeBytes: arrayBuffer.byteLength
    };
    
    chunkQueue.push(chunk);
    this.currentBufferSize += chunk.sizeBytes;
  }
};

// When yielding chunk:
if (chunkQueue.length > 0) {
  const chunk = chunkQueue.shift()!;
  this.currentBufferSize -= chunk.sizeBytes;
  yield chunk;
}
```

---

## –§–ê–ó–ê 3: Streaming Audio Player (4 —á–∞—Å–∞)

**–ò—Å–ø–æ–ª—å–∑—É–µ–º Chunked Files Strategy** (—Ç.–∫. Progressive Loading —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç)

### 3.1 Chunked Streaming Player (2.5 —á–∞—Å–∞)

**–ù–æ–≤—ã–π —Ñ–∞–π–ª:** `src/services/streaming-audio-player-chunked.ts`

```typescript
import * as FileSystem from 'expo-file-system/legacy';
import { Audio } from 'expo-av';
import { StreamingPlayerState, StreamingPlayerConfig, AudioChunk, StreamingMetrics } from '../types';
import { createWavFile, arrayBufferToBase64, calculateAudioDuration } from '../utils/audio-conversion';
import { STREAMING_CONFIG } from '../config/streaming-config';

/**
 * Chunked Files Strategy Player
 * Creates multiple mini WAV files and plays them sequentially
 */
class ChunkedStreamingPlayer {
  private state: StreamingPlayerState = 'idle';
  private chunkFiles: string[] = [];
  private currentSound: Audio.Sound | null = null;
  private nextSound: Audio.Sound | null = null;
  private playbackQueue: AudioChunk[][] = [];
  private config: StreamingPlayerConfig;
  private metrics: StreamingMetrics;
  
  private readonly CHUNKS_PER_FILE = 5; // ~200-250ms per file at 16kHz
  private readonly PRELOAD_THRESHOLD = 0.8; // Start preloading at 80% of current file
  
  constructor(config?: Partial<StreamingPlayerConfig>) {
    this.config = {
      minBufferMs: config?.minBufferMs || STREAMING_CONFIG.minBufferMs,
      targetBufferMs: config?.targetBufferMs || STREAMING_CONFIG.targetBufferMs,
      chunkSampleRate: 16000,
      maxRetries: 3,
      strategy: 'chunked'
    };
    
    this.metrics = this.createEmptyMetrics();
  }
  
  /**
   * Play audio stream from AsyncGenerator
   */
  async playStream(
    chunkGenerator: AsyncGenerator<AudioChunk, void, unknown>
  ): Promise<void> {
    console.log('üéµ [Chunked Player] Starting playback...');
    this.state = 'buffering';
    this.metrics = this.createEmptyMetrics();
    this.metrics.generationStart = Date.now();
    
    let accumulatedChunks: AudioChunk[] = [];
    let fileIndex = 0;
    let isFirstFile = true;
    
    try {
      // Process chunks from generator
      for await (const chunk of chunkGenerator) {
        this.metrics.totalChunks++;
        this.metrics.totalBytes += chunk.sizeBytes;
        
        if (this.metrics.firstChunkTime === null) {
          this.metrics.firstChunkTime = Date.now();
          console.log(`üéØ [Chunked Player] First chunk in ${this.metrics.firstChunkTime - this.metrics.generationStart}ms`);
        }
        
        accumulatedChunks.push(chunk);
        
        // Create file when we have enough chunks
        if (accumulatedChunks.length >= this.CHUNKS_PER_FILE) {
          const filepath = await this.createChunkFile(accumulatedChunks, fileIndex);
          fileIndex++;
          
          console.log(`üì¶ [Chunked Player] Created file #${fileIndex}: ${filepath}`);
          
          // Play first file immediately after min buffer
          if (isFirstFile) {
            const bufferDuration = calculateAudioDuration(
              accumulatedChunks.reduce((sum, c) => sum + c.sizeBytes, 0)
            );
            
            if (bufferDuration >= this.config.minBufferMs) {
              console.log(`‚úÖ [Chunked Player] Min buffer reached (${bufferDuration}ms) - starting playback`);
              await this.playFile(filepath);
              this.state = 'playing';
              this.metrics.firstPlayTime = Date.now();
              isFirstFile = false;
            }
          } else {
            // Preload next file
            await this.preloadNextFile(filepath);
          }
          
          accumulatedChunks = [];
        }
      }
      
      // Handle remaining chunks
      if (accumulatedChunks.length > 0) {
        const filepath = await this.createChunkFile(accumulatedChunks, fileIndex);
        console.log(`üì¶ [Chunked Player] Created final file: ${filepath}`);
        
        if (isFirstFile) {
          await this.playFile(filepath);
          this.state = 'playing';
          this.metrics.firstPlayTime = Date.now();
        } else {
          await this.preloadNextFile(filepath);
        }
      }
      
      // Wait for all files to finish playing
      await this.waitForCompletion();
      
      this.state = 'completed';
      console.log('‚úÖ [Chunked Player] Playback completed');
      console.log(`üìä [Chunked Player] Stats:`, this.getStats());
      
    } catch (error) {
      console.error('‚ùå [Chunked Player] Playback error:', error);
      this.state = 'error';
      throw error;
    } finally {
      await this.cleanup();
    }
  }
  
  /**
   * Create WAV file from chunks
   */
  private async createChunkFile(
    chunks: AudioChunk[],
    index: number
  ): Promise<string> {
    const pcmBuffers = chunks.map(c => c.data);
    const wavBuffer = createWavFile(pcmBuffers, this.config.chunkSampleRate);
    const base64 = arrayBufferToBase64(wavBuffer);
    
    const filename = `stream_chunk_${Date.now()}_${index}.wav`;
    const filepath = `${FileSystem.cacheDirectory}${filename}`;
    
    await FileSystem.writeAsStringAsync(filepath, base64, {
      encoding: 'base64'
    });
    
    this.chunkFiles.push(filepath);
    return filepath;
  }
  
  /**
   * Play a single file
   */
  private async playFile(filepath: string): Promise<void> {
    console.log(`üîä [Chunked Player] Playing: ${filepath}`);
    
    try {
      const { sound } = await Audio.Sound.createAsync(
        { uri: filepath },
        { shouldPlay: true, volume: 1.0 }
      );
      
      this.currentSound = sound;
      
      // Setup playback monitoring for preloading
      sound.setOnPlaybackStatusUpdate((status) => {
        if (status.isLoaded) {
          const progress = status.positionMillis / (status.durationMillis || 1);
          
          // Preload next file when current reaches threshold
          if (progress >= this.PRELOAD_THRESHOLD && this.nextSound === null) {
            const currentIndex = this.chunkFiles.indexOf(filepath);
            const nextFilepath = this.chunkFiles[currentIndex + 1];
            
            if (nextFilepath) {
              console.log(`‚è≠Ô∏è [Chunked Player] Preloading next file...`);
              this.preloadNextFile(nextFilepath);
            }
          }
          
          // Switch to next file when current finishes
          if (status.didJustFinish) {
            console.log(`‚úÖ [Chunked Player] File finished: ${filepath}`);
            this.switchToNextFile();
          }
        }
      });
      
    } catch (error) {
      console.error(`‚ùå [Chunked Player] Play error:`, error);
      throw error;
    }
  }
  
  /**
   * Preload next file
   */
  private async preloadNextFile(filepath: string): Promise<void> {
    try {
      const { sound } = await Audio.Sound.createAsync(
        { uri: filepath },
        { shouldPlay: false, volume: 1.0 }
      );
      
      this.nextSound = sound;
      console.log(`‚úÖ [Chunked Player] Preloaded: ${filepath}`);
      
    } catch (error) {
      console.error(`‚ùå [Chunked Player] Preload error:`, error);
    }
  }
  
  /**
   * Switch to next preloaded file
   */
  private async switchToNextFile(): Promise<void> {
    if (this.currentSound) {
      await this.currentSound.unloadAsync();
      this.currentSound = null;
    }
    
    if (this.nextSound) {
      const switchStart = Date.now();
      
      this.currentSound = this.nextSound;
      this.nextSound = null;
      
      await this.currentSound.playAsync();
      
      const switchTime = Date.now() - switchStart;
      console.log(`üîÑ [Chunked Player] Switched in ${switchTime}ms`);
      
      if (switchTime > 100) {
        console.warn(`‚ö†Ô∏è [Chunked Player] Slow switch detected: ${switchTime}ms`);
      }
    }
  }
  
  /**
   * Wait for all files to complete
   */
  private async waitForCompletion(): Promise<void> {
    return new Promise((resolve) => {
      const checkInterval = setInterval(async () => {
        if (!this.currentSound && !this.nextSound) {
          clearInterval(checkInterval);
          resolve();
        }
        
        if (this.currentSound) {
          const status = await this.currentSound.getStatusAsync();
          if (status.isLoaded && status.didJustFinish && !this.nextSound) {
            clearInterval(checkInterval);
            resolve();
          }
        }
      }, 100);
    });
  }
  
  /**
   * Stop playback
   */
  async stop(): Promise<void> {
    console.log('‚èπÔ∏è [Chunked Player] Stopping...');
    
    if (this.currentSound) {
      await this.currentSound.stopAsync();
      await this.currentSound.unloadAsync();
      this.currentSound = null;
    }
    
    if (this.nextSound) {
      await this.nextSound.unloadAsync();
      this.nextSound = null;
    }
    
    this.state = 'idle';
  }
  
  /**
   * Get current state
   */
  getState(): StreamingPlayerState {
    return this.state;
  }
  
  /**
   * Get statistics
   */
  getStats(): StreamingMetrics {
    return {
      ...this.metrics,
      averageChunkSize: this.metrics.totalChunks > 0 
        ? this.metrics.totalBytes / this.metrics.totalChunks 
        : 0,
      get timeToFirstChunk() {
        return this.firstChunkTime ? this.firstChunkTime - this.generationStart : null;
      },
      get timeToFirstPlay() {
        return this.firstPlayTime ? this.firstPlayTime - this.generationStart : null;
      },
      get totalLatency() {
        return this.firstPlayTime ? this.firstPlayTime - this.generationStart : null;
      }
    };
  }
  
  /**
   * Cleanup resources
   */
  private async cleanup(): Promise<void> {
    console.log('üßπ [Chunked Player] Cleaning up...');
    
    // Unload sounds
    if (this.currentSound) {
      await this.currentSound.unloadAsync();
      this.currentSound = null;
    }
    
    if (this.nextSound) {
      await this.nextSound.unloadAsync();
      this.nextSound = null;
    }
    
    // Delete temporary files
    for (const filepath of this.chunkFiles) {
      try {
        await FileSystem.deleteAsync(filepath, { idempotent: true });
      } catch (error) {
        console.warn(`‚ö†Ô∏è [Chunked Player] Failed to delete: ${filepath}`);
      }
    }
    
    this.chunkFiles = [];
    console.log('‚úÖ [Chunked Player] Cleanup complete');
  }
  
  /**
   * Create empty metrics object
   */
  private createEmptyMetrics(): StreamingMetrics {
    return {
      generationStart: 0,
      firstChunkTime: null,
      firstPlayTime: null,
      totalChunks: 0,
      totalBytes: 0,
      bufferUnderruns: 0,
      averageChunkSize: 0,
      get timeToFirstChunk() { return null; },
      get timeToFirstPlay() { return null; },
      get totalLatency() { return null; }
    };
  }
}

export default ChunkedStreamingPlayer;
```

### 3.2 Periodic Cleanup Service (30 –º–∏–Ω)

**–ù–æ–≤—ã–π —Ñ–∞–π–ª:** `src/services/temp-file-cleanup-service.ts`

```typescript
import * as FileSystem from 'expo-file-system/legacy';

/**
 * Cleanup old temporary audio files
 * Runs on app start and periodically
 */
class TempFileCleanupService {
  private cleanupInterval: NodeJS.Timeout | null = null;
  
  /**
   * Start periodic cleanup
   */
  start(): void {
    if (this.cleanupInterval) return;
    
    console.log('üßπ [Cleanup] Starting periodic cleanup...');
    
    // Run immediately
    this.cleanupOldFiles();
    
    // Run every 5 minutes
    this.cleanupInterval = setInterval(() => {
      this.cleanupOldFiles();
    }, 5 * 60 * 1000);
  }
  
  /**
   * Stop periodic cleanup
   */
  stop(): void {
    if (this.cleanupInterval) {
      clearInterval(this.cleanupInterval);
      this.cleanupInterval = null;
      console.log('üßπ [Cleanup] Stopped');
    }
  }
  
  /**
   * Cleanup old files
   */
  private async cleanupOldFiles(): Promise<void> {
    try {
      const cacheDir = FileSystem.cacheDirectory;
      if (!cacheDir) return;
      
      const files = await FileSystem.readDirectoryAsync(cacheDir);
      const now = Date.now();
      const MAX_AGE_MS = 30 * 60 * 1000; // 30 minutes
      
      let deletedCount = 0;
      let deletedBytes = 0;
      
      for (const filename of files) {
        // Only process our temp files
        if (!filename.startsWith('stream_chunk_') && 
            !filename.startsWith('speech_') &&
            !filename.startsWith('openai_speech_')) {
          continue;
        }
        
        const filepath = `${cacheDir}${filename}`;
        
        try {
          const info = await FileSystem.getInfoAsync(filepath);
          
          if (info.exists && info.modificationTime) {
            const age = now - info.modificationTime * 1000;
            
            if (age > MAX_AGE_MS) {
              await FileSystem.deleteAsync(filepath, { idempotent: true });
              deletedCount++;
              deletedBytes += info.size || 0;
            }
          }
        } catch (error) {
          console.warn(`‚ö†Ô∏è [Cleanup] Failed to process: ${filename}`);
        }
      }
      
      if (deletedCount > 0) {
        const mb = (deletedBytes / (1024 * 1024)).toFixed(2);
        console.log(`üßπ [Cleanup] Deleted ${deletedCount} files (${mb} MB)`);
      }
      
    } catch (error) {
      console.error('‚ùå [Cleanup] Error:', error);
    }
  }
}

export default new TempFileCleanupService();
```

---

## –§–ê–ó–ê 4: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ TTSService (2.5 —á–∞—Å–∞)

### 4.1 –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ TTSService (2 —á–∞—Å–∞)

**–§–∞–π–ª:** `src/services/tts-service.ts`

**–ò–∑–º–µ–Ω–µ–Ω–∏—è:**

```typescript
import cartesiaStreaming from './cartesia-streaming-service';
import ChunkedStreamingPlayer from './streaming-audio-player-chunked';
import tempFileCleanup from './temp-file-cleanup-service';
import { STREAMING_CONFIG } from '../config/streaming-config';

class TTSService {
  // Existing fields...
  
  // NEW: Streaming fields
  private useStreamingForCartesia: boolean = STREAMING_CONFIG.enabled;
  private streamingPlayer: ChunkedStreamingPlayer | null = null;
  private currentStreamingContext: string | null = null;
  
  constructor() {
    this.initialize();
    this.openaiApiKey = process.env.EXPO_PUBLIC_OPENAI_API_KEY;
    this.loadSettings();
    
    // NEW: Initialize streaming if enabled
    if (this.useStreamingForCartesia) {
      console.log('‚úÖ [TTS] Streaming TTS enabled');
      this.streamingPlayer = new ChunkedStreamingPlayer();
      
      // Start cleanup service
      tempFileCleanup.start();
      
      // Pre-connect WebSocket for faster first request
      cartesiaStreaming.connect().catch(err => {
        console.warn('‚ö†Ô∏è [TTS] Pre-connection failed:', err);
      });
    }
  }
  
  // ========================
  // UPDATED speak() METHOD
  // ========================
  
  async speak(
    text: string,
    options?: {
      emotion?: string;
      speed?: number;
      emotionLevel?: string[];
      autoPlay?: boolean;
    }
  ): Promise<boolean> {
    // Mute check
    if (this.isMuted) {
      console.log(`üîá [TTS] Muted - skipping speech`);
      return true;
    }
    
    try {
      console.log(`üéôÔ∏è [TTS] Speaking: "${text.substring(0, 50)}..."`);
      
      // Route to appropriate provider
      if (this.ttsProvider === 'openai') {
        return await this.speakOpenAI(text, options);
      } else {
        // Cartesia with streaming support
        if (this.useStreamingForCartesia) {
          try {
            return await this.speakCartesiaStreaming(text, options);
          } catch (error) {
            console.warn('‚ö†Ô∏è [TTS] Streaming failed, falling back to REST:', error);
            return await this.speakCartesiaRest(text, options);
          }
        } else {
          return await this.speakCartesiaRest(text, options);
        }
      }
      
    } catch (error) {
      console.error("‚ùå [TTS] Speak error:", error);
      return false;
    }
  }
  
  // ========================
  // NEW STREAMING METHOD
  // ========================
  
  /**
   * Speak using Cartesia streaming
   */
  private async speakCartesiaStreaming(
    text: string,
    options?: {
      emotion?: string;
      speed?: number;
      emotionLevel?: string[];
      autoPlay?: boolean;
    }
  ): Promise<boolean> {
    if (!this.streamingPlayer) {
      throw new Error('Streaming player not initialized');
    }
    
    console.log('üéôÔ∏è [TTS] Using Cartesia streaming...');
    
    // Cancel previous streaming if any
    if (this.currentStreamingContext) {
      cartesiaStreaming.cancelGeneration();
      await this.streamingPlayer.stop();
    }
    
    const VOICE_ID = "e07c00bc-4134-4eae-9ea4-1a55fb45746b";
    
    // Map speed number to Cartesia speed string
    let speedString: 'slowest' | 'slow' | 'normal' | 'fast' | 'fastest' = 'normal';
    if (options?.speed) {
      if (options.speed <= 0.75) speedString = 'slowest';
      else if (options.speed <= 0.9) speedString = 'slow';
      else if (options.speed >= 1.25) speedString = 'fastest';
      else if (options.speed >= 1.1) speedString = 'fast';
    }
    
    try {
      // Generate unique context
      const contextId = `tts-${Date.now()}`;
      this.currentStreamingContext = contextId;
      
      // Create AsyncGenerator
      const chunkGenerator = cartesiaStreaming.generateAudioStream({
        voiceId: VOICE_ID,
        text: text,
        emotion: options?.emotionLevel,
        speed: speedString,
        onFirstChunk: (latency) => {
          console.log(`üéØ [TTS] First chunk latency: ${latency}ms`);
        },
        onComplete: () => {
          console.log('‚úÖ [TTS] Streaming generation complete');
        },
        onError: (error) => {
          console.error('‚ùå [TTS] Streaming generation error:', error);
        }
      });
      
      // Play stream
      if (options?.autoPlay !== false) {
        await this.streamingPlayer.playStream(chunkGenerator);
      }
      
      return true;
      
    } catch (error) {
      console.error('‚ùå [TTS] Streaming error:', error);
      throw error;
    } finally {
      this.currentStreamingContext = null;
    }
  }
  
  // ========================
  // RENAMED REST METHOD
  // ========================
  
  /**
   * Speak using Cartesia REST API (renamed from fetchCartesiaAudioFile)
   */
  private async speakCartesiaRest(
    text: string,
    options?: {
      emotion?: string;
      speed?: number;
      emotionLevel?: string[];
      autoPlay?: boolean;
    }
  ): Promise<boolean> {
    console.log('üéôÔ∏è [TTS] Using Cartesia REST...');
    
    const audioFile = await this.fetchCartesiaAudioFileRest(text, options);
    
    if (!audioFile) {
      console.error("‚ùå [TTS] Failed to fetch audio");
      return false;
    }
    
    if (options?.autoPlay !== false) {
      return await this.playAudioFile(audioFile, options?.speed);
    }
    
    return true;
  }
  
  /**
   * Fetch audio file from Cartesia REST API
   * (Same as old fetchCartesiaAudioFile but renamed)
   */
  private async fetchCartesiaAudioFileRest(
    text: string,
    options?: {
      emotion?: string;
      speed?: number;
      emotionLevel?: string[];
    }
  ): Promise<string | null> {
    // EXACT SAME CODE as existing fetchCartesiaAudioFile
    // Just rename and remove hardcoded key
    
    const API_KEY = process.env.EXPO_PUBLIC_CARTESIA_API_KEY; // ‚úÖ FIXED
    
    if (!API_KEY) {
      console.error('‚ùå [TTS] Cartesia API key not configured');
      return null;
    }
    
    // ... rest of existing implementation ...
    
    // (keep all existing code, just use API_KEY from env)
  }
  
  // ========================
  // RENAMED OPENAI METHOD
  // ========================
  
  /**
   * Speak using OpenAI TTS (renamed for consistency)
   */
  private async speakOpenAI(
    text: string,
    options?: {
      emotion?: string;
      speed?: number;
      emotionLevel?: string[];
      autoPlay?: boolean;
    }
  ): Promise<boolean> {
    console.log('üéôÔ∏è [TTS] Using OpenAI...');
    
    const audioFile = await this.fetchOpenAIAudioFile(text, options);
    
    if (!audioFile) {
      console.error("‚ùå [TTS] Failed to fetch audio");
      return false;
    }
    
    if (options?.autoPlay !== false) {
      return await this.playAudioFile(audioFile, options?.speed);
    }
    
    return true;
  }
  
  // ========================
  // CLEANUP
  // ========================
  
  async cleanup(): Promise<void> {
    await this.stop();
    
    if (this.streamingPlayer) {
      await this.streamingPlayer.stop();
    }
    
    cartesiaStreaming.disconnect();
    tempFileCleanup.stop();
  }
}
```

### 4.2 Feature Flag Control (30 –º–∏–Ω)

**–î–æ–±–∞–≤–∏—Ç—å –≤ UI –Ω–∞—Å—Ç—Ä–æ–µ–∫:**

```typescript
// In settings screen

import { STREAMING_CONFIG } from '../config/streaming-config';

function SettingsScreen() {
  const [streamingEnabled, setStreamingEnabled] = useState(STREAMING_CONFIG.enabled);
  
  const toggleStreaming = async () => {
    const newValue = !streamingEnabled;
    setStreamingEnabled(newValue);
    
    // Save to AsyncStorage
    await AsyncStorage.setItem('streaming_enabled', newValue.toString());
    
    // Update config (requires app restart)
    Alert.alert(
      'Restart Required',
      'Please restart the app to apply streaming settings.',
      [{ text: 'OK' }]
    );
  };
  
  return (
    <View>
      {/* ... existing settings ... */}
      
      <View>
        <Text>Streaming TTS (Experimental)</Text>
        <Switch value={streamingEnabled} onValueChange={toggleStreaming} />
        <Text style={{ fontSize: 12, color: 'gray' }}>
          Reduces latency from ~2.5s to ~0.3s
        </Text>
      </View>
    </View>
  );
}
```

---

## üìä –¶–µ–ª–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏

**–¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ (REST API):**
- Time to first audio: ~2500ms
- Total request time: ~2500-3000ms
- Breakdown: Fetch=2000ms, ArrayBuffer=300ms, Save=200ms

**–¶–µ–ª–µ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ (Streaming):**
- Time to first chunk: <300ms ‚úÖ
- Time to first playback: <500ms ‚úÖ
- Total latency improvement: ~8x faster ‚úÖ

**–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞:**
- Audio quality: No degradation
- Playback continuity: <50ms gaps between chunks
- Memory usage: <10MB buffer
- Network reliability: >95% success rate

---

## üö® Rollback Plan

**–ï—Å–ª–∏ Streaming –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç:**

1. **Immediate fallback** - —É–∂–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ —á–µ—Ä–µ–∑ try/catch
2. **Feature flag disable** - —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å `CARTESIA_STREAMING_ENABLED=false`
3. **Code rollback** - –≤–µ—Å—å streaming –∫–æ–¥ –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω, –ª–µ–≥–∫–æ —É–¥–∞–ª–∏—Ç—å
4. **Alternative optimizations:**
   - Pre-generate common phrases
   - HTTP/2 connection pooling
   - Parallel requests for multiple questions
   - Client-side caching

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ –¥–ª—è rollback:**
- ‚ùå Success rate <80% –≤ production
- ‚ùå Playback artifacts –≤ >10% —Å–ª—É—á–∞–µ–≤
- ‚ùå Latency improvement <3x
- ‚ùå Memory leaks –∏–ª–∏ crashes

---

## ‚úÖ Success Criteria (Final)

**Technical:**
- ‚úÖ WebSocket stable connection >95%
- ‚úÖ First chunk latency <300ms avg
- ‚úÖ Playback starts <500ms avg
- ‚úÖ No audio artifacts or gaps
- ‚úÖ Memory usage <10MB
- ‚úÖ Cleanup works correctly
- ‚úÖ Fallback to REST works

**User Experience:**
- ‚úÖ Noticeably faster responses
- ‚úÖ Smooth playback
- ‚úÖ No quality degradation
- ‚úÖ Works on iOS and Android

**Code Quality:**
- ‚úÖ Well-documented
- ‚úÖ Error handling robust
- ‚úÖ Easy to disable/rollback
- ‚úÖ Metrics logged

---

## üìù Testing Checklist

**Unit Tests:**
- [ ] WAV header creation
- [ ] PCM merging
- [ ] Base64 conversion
- [ ] Duration calculation

**Integration Tests:**
- [ ] WebSocket connection
- [ ] Chunk receiving
- [ ] File creation
- [ ] Playback sequencing

**End-to-End Tests:**
- [ ] Full streaming flow
- [ ] Network interruption recovery
- [ ] Memory cleanup
- [ ] Concurrent requests

**Device Tests:**
- [ ] iOS (different versions)
- [ ] Android (different versions)
- [ ] Different network conditions
- [ ] Background/foreground switching

---

## üéØ Estimated Timeline

- **–§–ê–ó–ê 0 (PoC):** 4-5 hours
- **–§–ê–ó–ê 1 (Types):** 1.5 hours
- **–§–ê–ó–ê 2 (WebSocket):** 3 hours
- **–§–ê–ó–ê 3 (Player):** 4 hours
- **–§–ê–ó–ê 4 (Integration):** 2.5 hours
- **Testing & Polish:** 3 hours

**Total:** ~18-20 hours (~2.5 days)

---

## üîß Troubleshooting Guide

**WebSocket –Ω–µ –ø–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è:**
- –ü—Ä–æ–≤–µ—Ä–∏—Ç—å API key
- –ü—Ä–æ–≤–µ—Ä–∏—Ç—å network permissions
- –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –±–µ–∑ VPN
- –õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å WebSocket errors

**–ß–∞–Ω–∫–∏ –Ω–µ –ø—Ä–∏—Ö–æ–¥—è—Ç:**
- –ü—Ä–æ–≤–µ—Ä–∏—Ç—å request format
- –õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ WebSocket messages
- –ü—Ä–æ–≤–µ—Ä–∏—Ç—å voice_id –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å

**Audio artifacts:**
- –ü—Ä–æ–≤–µ—Ä–∏—Ç—å WAV header
- –ü—Ä–æ–≤–µ—Ä–∏—Ç—å PCM byte order
- –ü—Ä–æ–≤–µ—Ä–∏—Ç—å sample rate consistency
- –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Ñ—Ä–∞–∑–∞—Ö

**Memory leaks:**
- –ü—Ä–æ–≤–µ—Ä–∏—Ç—å cleanup –≤—ã–∑–æ–≤—ã
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å React DevTools Profiler
- –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å FileSystem.cacheDirectory size
- –ü—Ä–æ–≤–µ—Ä–∏—Ç—å unloadAsync() –¥–ª—è –≤—Å–µ—Ö Sound objects

**Slow switching –º–µ–∂–¥—É —Ñ–∞–π–ª–∞–º–∏:**
- –£–≤–µ–ª–∏—á–∏—Ç—å PRELOAD_THRESHOLD
- –£–º–µ–Ω—å—à–∏—Ç—å CHUNKS_PER_FILE
- –ü—Ä–æ–≤–µ—Ä–∏—Ç—å FileSystem performance
- –õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å switch timing

---

**END OF PLAN**
